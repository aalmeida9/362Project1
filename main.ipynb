{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import statistics\n",
    "import math\n",
    "import random\n",
    "from scipy import stats\n",
    "from statsmodels.graphics.mosaicplot import mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Import, and slice data (2nd sample group first 100 responses from revised survey, not including 1st sample group of 20)\n",
    "\n",
    "df = pd.read_csv(\"UMass Sustainability Initiative.csv\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#basic data analysis for quantitive data, habits and age distribution\n",
    "\n",
    "def distribution(df):\n",
    "    print(f'The mean is {df.mean()} the Standard Erorr of the mean is {stats.sem(df, axis=None, ddof=0)}')\n",
    "    print(f'The variance is {statistics.variance(df)} the standard deviation is {df.std()}')\n",
    "    print(f'The min is {df.min()}, Q1 is {np.quantile(df, .25)}, median is {df.median()}, Q3 is {np.quantile(df, .75)}, max is {df.max()}')\n",
    "    print(f'Skewness: {stats.skew(df)}')\n",
    "    first_quartile = np.quantile(df, .25)\n",
    "    third_quartile = np.quantile(df, .75)\n",
    "    IQR = third_quartile - first_quartile \n",
    "    low_value = first_quartile - (IQR * 1.5)\n",
    "    high_value = third_quartile + (IQR * 1.5)\n",
    "    outliers = []\n",
    "    outliers.clear\n",
    "    for i in df:\n",
    "        if low_value > i:\n",
    "            outliers.append(i)\n",
    "        elif high_value < i:\n",
    "            outliers.append(i)\n",
    "    outliers.sort()\n",
    "    print(f'Outliers: {outliers}')\n",
    "        \n",
    "#distribution(df['Habits'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Year</th>\n",
       "      <th>Major</th>\n",
       "      <th>On Campus</th>\n",
       "      <th>Location</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>Rules</th>\n",
       "      <th>Likelihood</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Items</th>\n",
       "      <th>Habits</th>\n",
       "      <th>Whats the best way to reach you for the prize draw? (Enter your Email, Phone, etc. )</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020/02/18 4:03:42 PM AST</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sophomore</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Birch</td>\n",
       "      <td>Often</td>\n",
       "      <td>Sustainability;Ease of Access</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Paper;Cardboard;Plastic Bottles;Glass Bottles;...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/18 4:05:49 PM AST</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Aspen</td>\n",
       "      <td>Always</td>\n",
       "      <td>Sustainability;Habit</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Paper;Cardboard;Plastic Bottles;Glass Bottles;...</td>\n",
       "      <td>4</td>\n",
       "      <td>jegan2@umassd.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020/02/18 4:09:10 PM AST</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Always</td>\n",
       "      <td>Habit</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Paper;Cardboard;Plastic Bottles;Glass Bottles;...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Timestamp Age Gender Occupation       Year  \\\n",
       "0  2020/02/18 4:03:42 PM AST  20   Male        NaN  Sophomore   \n",
       "1  2020/02/18 4:05:49 PM AST  20   Male        NaN     Junior   \n",
       "2  2020/02/18 4:09:10 PM AST  23   Male        NaN     Junior   \n",
       "\n",
       "              Major On Campus Location Frequency  \\\n",
       "0  Computer Science       Yes    Birch     Often   \n",
       "1  Computer Science       Yes    Aspen    Always   \n",
       "2  Computer Science        No      NaN    Always   \n",
       "\n",
       "                       Reasoning Rules Likelihood Symbol  \\\n",
       "0  Sustainability;Ease of Access   Yes        Yes    Yes   \n",
       "1           Sustainability;Habit    No        Yes     No   \n",
       "2                          Habit   Yes        NaN     No   \n",
       "\n",
       "                                               Items  Habits  \\\n",
       "0  Paper;Cardboard;Plastic Bottles;Glass Bottles;...       3   \n",
       "1  Paper;Cardboard;Plastic Bottles;Glass Bottles;...       4   \n",
       "2  Paper;Cardboard;Plastic Bottles;Glass Bottles;...       2   \n",
       "\n",
       "  Whats the best way to reach you for the prize draw? (Enter your Email, Phone, etc. )  \n",
       "0                                                NaN                                    \n",
       "1                                  jegan2@umassd.edu                                    \n",
       "2                                                NaN                                    "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Cleaning\n",
    "\n",
    "df.rename(columns = {'How old are you?':'Age', 'What is your gender?':'Gender', 'What occupation do you hold in the University?':'Occupation',\n",
    "                     'What year are you?':'Year', 'What is your major?':'Major',\n",
    "                     'Do you live on campus?':'On Campus', 'If you do live on campus, where do live?':'Location',\n",
    "                     'How often do you recycle?':'Frequency', \"Why do you recycle? (Don't answer if you don't)\":'Reasoning',\n",
    "                     'Are the recycling rules on campus clearly presented?':'Rules', \n",
    "                     'If not, if the recycling rules were clearer would you be more likely to recycle?':'Likelihood',\n",
    "                     'Do you look for the recycle symbol before recycling?':'Symbol', 'What items do you usually recycle?':'Items',\n",
    "                     'Did the survey overall make you think about your own personal recycling methods and habits?':'Habits',\n",
    "                     'Whats the best way to reach you for the prize draw? (Email, Phone, etc. )':'Prize'}, inplace = True)\n",
    "\n",
    "#fill with None?\n",
    "#df.fillna(None, inplace=True)\n",
    "\n",
    "#Splitting strings into arrays, not actually useful! Strings have useful methods see electronics cell below\n",
    "#df['Reasoning'] = df['Reasoning'].str.split(\";\", expand = False)\n",
    "#df['Items'] = df['Items'].str.split(\";\", expand = False)\n",
    "\n",
    "df['Reasoning'].fillna('Nothing', inplace = True) \n",
    "\n",
    "#Gender data cleaning...\n",
    "df['Gender'].replace(to_replace = \"Goblin\", value = \"other\", inplace = True) \n",
    "\n",
    "\n",
    "#age data cleaning....\n",
    "df['Age'].replace(to_replace = \"Twenty\", value = int(20), inplace = True) \n",
    "df['Age'].replace(dict.fromkeys(['I am banes', 'RECYCLING IS FOR NERDS'], int(20)), inplace = True)\n",
    "#df['Age'].replace(to_replace = 1, value = 20, inplace = True) \n",
    "\n",
    "#Replacing Majors with relevant groups, by engineers, Computer Science, Business \n",
    "#Replacing Majors with relevant groups, by engineers, Computer Science, Business \n",
    "df['Major'].replace(dict.fromkeys(['CS', 'CIS', 'Computer Science', 'Computer science', 'Computer science', 'Comp sci', 'Comp Sci', 'COMPUTER SCIENCE', 'Computer Science'], \n",
    "                                  'Computer Science'), inplace = True)\n",
    "df['Rules'].replace(dict.fromkeys([\"I didn't know there were any recycling rules!\"], \"I didn't know\"), inplace = True)\n",
    "df['Major'].replace(dict.fromkeys(['MIS', 'Accounting', 'Marketing'], 'College of Business'), inplace = True)\n",
    "\n",
    "#focus group 1 is now df1\n",
    "df1 = df.iloc[0:100]\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are 95% confident that the interval 4.0398538043813605 to 3.8570071821657246 contains the population mean based on the sample set\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Frequency_as_int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Frequency_as_int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9591f81b474a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz_score\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfrequency_std_div\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdivisor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'we are 95% confident that the interval'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfrequency_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'to'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrequency_mean\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'contains the population mean based on the sample set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mcorrelate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Frequency_as_int'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Correlation: {correlate}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Frequency_as_int'"
     ]
    }
   ],
   "source": [
    "#CONFIDENCE INTERVAL FOR FREQUENCY OF RECYCLING\n",
    "#repacling all strings with ints in NEW dataframe column\n",
    "#if you want to use for the WHOLE data set, change df to whatever the name is of the dataframe\n",
    "#that contains all 446 participants\n",
    "df['Frequency_as_int'] = df['Frequency']    \n",
    "df['Frequency_as_int'] = df['Frequency_as_int'].replace('Always', 5)\n",
    "df['Frequency_as_int'] = df['Frequency_as_int'].replace('Often', 4)\n",
    "df['Frequency_as_int'] = df['Frequency_as_int'].replace('Sometimes', 3)\n",
    "df['Frequency_as_int'] = df['Frequency_as_int'].replace('Rarely', 2)\n",
    "df['Frequency_as_int'] = df['Frequency_as_int'].replace('Never', 1)\n",
    "#function: mean +- z (of alpha/2) * (std dev/ sqrt(n))\n",
    "frequency_mean = df['Frequency_as_int'].mean()\n",
    "frequency_std_div = df['Frequency_as_int'].std()\n",
    "#using the equation we get 1-((1 - 95)/2)\n",
    "#z_score is 1.96 for 95 percent confidence\n",
    "z_score = 1.96\n",
    "divisor = math.sqrt(len(df))\n",
    "confidence = z_score * (frequency_std_div/divisor)\n",
    "print('we are 95% confident that the interval', confidence+frequency_mean, 'to', frequency_mean-confidence, 'contains the population mean based on the sample set')\n",
    "correlate = np.corrcoef(df1['Age'], df1['Frequency_as_int'])\n",
    "print(f'Correlation: {correlate}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Pick a random winner for the prize\n",
    "# df[random.randint(1, len(df))], first attempt doesn't work\n",
    "df.loc[df.index == random.randint(1, len(df))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# age data analysis, pain in the neck\n",
    "#df['Age'].fillna(method = 'ffill')\n",
    "#df.reset_index(drop=True)\n",
    "#df['Age'].dtype #object type\n",
    "df['Age'].value_counts()\n",
    "#df1.Age = df1.Age.astype(int)\n",
    "#df.Age = df.Age.astype(int)\n",
    "#print(df['Age'].mean(skipna=True))\n",
    "\n",
    "distribution(df['Age'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# habits data analysis, luckily a lot easier\n",
    "#print(df['Habits'].mean(skipna=True))\n",
    "\n",
    "distribution(df['Habits'])\n",
    "df['Habits'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic data analysis for qualtitve data, Major Location Frequency Reasoning Items ... etc\n",
    "\n",
    "#to be filled in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Sorting entries (potential group of interest could be people with low habits, majority of people had high schore for habits)\n",
    "\n",
    "df.sort_values('Major', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initial data analysis with Bar plots on recycling frequency (Focus Group Students)\n",
    "#we can assume that all first 100 surveys are students since we manually surveyed students with QR codes on our phones\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "x = np.arange(5)\n",
    "\n",
    "plt.bar(x, df1['Frequency'].value_counts(), align='center', alpha=0.5)\n",
    "plt.xticks(x, ('Always', 'Often', 'Sometimes', 'Rarely', 'Never'))\n",
    "plt.title('Frequency of Recycling Among Students')\n",
    "plt.xlabel('How often do you recycle?')\n",
    "plt.ylabel('Focus Group 2 Students')\n",
    "plt.show()\n",
    "#cumulative frequency would be cool on the graph above, Pareto Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data analysis on Items column, specifically electronic subset\n",
    "\n",
    "AC = df.Items.str.contains(pat = 'Electronics') \n",
    "#AC.value_counts().plot(kind='bar'), same as code below without formatting\n",
    "\n",
    "x = np.arange(2)\n",
    "\n",
    "plt.bar(x, AC.value_counts(), align='center', alpha=0.5)\n",
    "plt.xticks(x, (\"Doesn't Recycle Electronics\", 'Recycles Electronics'))\n",
    "plt.title('Students who Recycle Electronics')\n",
    "plt.xlabel('What items do you usually recycle?')\n",
    "plt.ylabel('Focus Group 2 Students')\n",
    "plt.show()\n",
    "\n",
    "#df1.Items.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mosaic plot\n",
    "m = df.groupby([\"Symbol\", \"Likelihood\"]).sum()\n",
    "\n",
    "mosaic(df, [\"Habits\", \"Symbol\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data analysis on Reasoning column specifically how manuy people put 'Sustainability' as a reason for them recycling \n",
    "\n",
    "df1 = df.Reasoning.str.contains(pat = 'Sustainability')\n",
    "df1.value_counts()\n",
    "df1.value_counts().plot(kind='bar')\n",
    "pl1 = df.Reasoning.str.contains('Sustainability').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data analysis on Reasoning column specifically how manuy people put 'Habit' as a reason for them recycling \n",
    "df2 = df.Reasoning.str.contains(pat = 'Habit')\n",
    "df2.value_counts()\n",
    "df2.value_counts().plot(kind='bar')\n",
    "pl2 = df.Reasoning.str.contains('Habit').sum()\n",
    "#print(df.Reasoning.str.contains('Habit').sum())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data analysis on Reasoning column specifically how manuy people put 'Ease of Access' as a reason for them recycling \n",
    "df3 = df.Reasoning.str.contains(pat = 'Ease of Access')\n",
    "df3.value_counts()\n",
    "df3.value_counts().plot(kind='bar')\n",
    "pl3 = df.Reasoning.str.contains('Ease of Access').sum()\n",
    "#print(df.Reasoning.str.contains('Ease of Access').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#prints graph of how many people chose what fro their reason for recycling \n",
    "#there is more than 100 answers because people could choose more than one thing, to my detriment\n",
    "print(df.Reasoning.str.contains('Sustainability').sum())    \n",
    "\n",
    "df4 = pd.DataFrame({'Reasons for Recycling':['Sustainability', 'Habit', 'Ease of Access'], 'Number of People':[pl1, pl2, pl3]}) \n",
    "ax = df4.plot.bar(x='Reasons for Recycling', y='Number of People', rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jonas' Distaster Area 2.0\n",
    "#plt.style.use('classic')\n",
    "#Recycling Frequency Pie Chart\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "labels = df['Frequency'].value_counts().index.tolist()\n",
    "\n",
    "wedges, texts, autotexts = ax1.pie(df['Frequency'].value_counts(), autopct='%1.1f%%', wedgeprops={'edgecolor': 'black'}, textprops=dict(color='w'))\n",
    "ax1.set_title('Recycling Frequency')\n",
    "\n",
    "ax1.legend(loc=\"center right\", bbox_to_anchor=(1, 0, 0.5, 1), labels= labels)\n",
    "plt.setp(autotexts, size=12, weight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender Bar Graph\n",
    "fig3, ax3 = plt.subplots()\n",
    "x = df['Gender'].value_counts().index.tolist()\n",
    "y = df['Gender'].value_counts().tolist()\n",
    "ax3.bar(x, y, edgecolor='black')\n",
    "\n",
    "\n",
    "ax3.set_axisbelow(True)\n",
    "ax3.set_xlabel('Genders')\n",
    "ax3.set_ylabel('Number of Students')\n",
    "ax3.set_title('Number of Students per Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age Box Plot\n",
    "fig4, ax4 = plt.subplots()\n",
    "\n",
    "ax4.boxplot(df['Age'], meanline=True, showmeans=True, sym='r+')\n",
    "\n",
    "ax4.set_axisbelow(True)\n",
    "ax4.set_xlabel('')\n",
    "ax4.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rules and likeliehood Mosaic\n",
    "#m = df.groupby(['Rules','Likelihood']).sum()\n",
    "mosaic(df, [\"Rules\", \"Likelihood\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Major Bar Graph\n",
    "fig5, ax5 = plt.subplots()\n",
    "x = df['Major'].value_counts().index.tolist()\n",
    "y = df['Major'].value_counts().tolist()\n",
    "ax5.barh(x, y, edgecolor='black')\n",
    "\n",
    "\n",
    "ax5.set_axisbelow(True)\n",
    "ax5.set_xlabel('Majors')\n",
    "ax5.set_ylabel('Number of Students')\n",
    "ax5.set_title('Number of Students per Major')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age V.S. Frequency Scatter Plot\n",
    "plt.scatter(x=df['Age'],\n",
    "            y=df['Habits'], alpha = 0.2)\n",
    "plt.title('Age V.S. Impact')\n",
    "plt.xticks(np.arange(0, 50, 10))\n",
    "plt.yticks(np.arange(0, 6, 1))\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Impact')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HAHAHAHAHA\n",
    "#print(df['Reasoning'][0])\n",
    "#print(len(df['Age']))\n",
    "\n",
    "#need num of people from ages 18-25 and 25+\n",
    "#need how many people slected each for each age \n",
    "\n",
    "sus18 = 0\n",
    "hab18 = 0\n",
    "ease18 = 0\n",
    "sus19= 0\n",
    "hab19 = 0\n",
    "ease19 = 0\n",
    "sus20 = 0\n",
    "hab20 = 0\n",
    "ease20 = 0\n",
    "sus21 = 0\n",
    "hab21 = 0\n",
    "ease21 = 0\n",
    "sus22 = 0\n",
    "hab22 = 0\n",
    "ease22 = 0\n",
    "sus23 = 0\n",
    "hab23 = 0\n",
    "ease23 = 0\n",
    "sus24 = 0\n",
    "hab24 = 0\n",
    "ease24 = 0\n",
    "sus25 = 0\n",
    "hab25 = 0\n",
    "ease25 = 0\n",
    "sus25_plus = 0\n",
    "hab25_plus = 0\n",
    "ease25_plus = 0\n",
    "\n",
    "for i in range (0, len(df['Age'])):\n",
    "    if df['Age'][i] == 18:\n",
    "        \n",
    "        print(df['Age'][i])\n",
    "        print(df['Reasoning'][i])\n",
    "        \n",
    "        if 'Sustainability' in df['Reasoning'][i]:\n",
    "            sus18+=1\n",
    "        elif 'Habit' in df['Reasoning'][i]:\n",
    "            hab18+=1\n",
    "        elif 'Ease of Access' in df['Reasoning'][i]:\n",
    "            ease18+=1\n",
    "            \n",
    "    elif df['Age'][i] == 19:\n",
    "        \n",
    "        print(df['Age'][i])\n",
    "        print(df['Reasoning'][i])\n",
    "        \n",
    "        if 'Sustainability' in df['Reasoning'][i]:\n",
    "            sus19+=1\n",
    "        elif 'Habit' in df['Reasoning'][i]:\n",
    "            hab19+=1\n",
    "        elif 'Ease of Access' in df['Reasoning'][i]:\n",
    "            ease19+=1\n",
    "            \n",
    "    elif df['Age'][i] == 20:\n",
    "        if 'Sustainability' in df['Reasoning'][i]:\n",
    "            sus20+=1\n",
    "        elif 'Habit' in df['Reasoning'][i]:\n",
    "            hab20+=1\n",
    "        elif 'Ease of Access' in df['Reasoning'][i]:\n",
    "            ease20+=1\n",
    "            \n",
    "    elif df['Age'][i] == 21:\n",
    "        \n",
    "        print(df['Age'][i])\n",
    "        print(df['Reasoning'][i])\n",
    "        print(i)\n",
    "        \n",
    "        if 'Sustainability' in df['Reasoning'][i]:\n",
    "            sus21+=1\n",
    "        elif 'Habit' in df['Reasoning'][i]:\n",
    "            hab21+=1\n",
    "        elif 'Ease of Access' in df['Reasoning'][i]:\n",
    "            ease21+=1\n",
    "        \n",
    "    elif df['Age'][i] == 22:\n",
    "        if 'Sustainability' in df['Reasoning'][i]:\n",
    "            sus22+=1\n",
    "        elif 'Habit' in df['Reasoning'][i]:\n",
    "            hab22+=1\n",
    "        elif 'Ease of Access' in df['Reasoning'][i]:\n",
    "            ease22+=1\n",
    "        \n",
    "    elif df['Age'][i] == 23:\n",
    "        if 'Sustainability' in df['Reasoning'][i]:\n",
    "            sus23+=1\n",
    "        elif 'Habit' in df['Reasoning'][i]:\n",
    "            hab23+=1\n",
    "        elif 'Ease of Access' in df['Reasoning'][i]:\n",
    "            ease23+=1\n",
    "        \n",
    "    elif df['Age'][i] == 24:\n",
    "        if 'Sustainability' in df['Reasoning'][i]:\n",
    "            sus24+=1\n",
    "        elif 'Habit' in df['Reasoning'][i]:\n",
    "            hab24+=1\n",
    "        elif 'Ease of Access' in df['Reasoning'][i]:\n",
    "            ease24+=1\n",
    "        \n",
    "    elif df['Age'][i] == 25:\n",
    "        if 'Sustainability' in df['Reasoning'][i]:\n",
    "            sus25+=1\n",
    "        elif 'Habit' in df['Reasoning'][i]:\n",
    "            hab25+=1\n",
    "        elif 'Ease of Access' in df['Reasoning'][i]:\n",
    "            ease25+=1\n",
    "        \n",
    "    elif df['Age'][i] > 25:\n",
    "        if 'Sustainability' in df['Reasoning'][i]:\n",
    "            sus25_plus+=1\n",
    "        elif 'Habit' in df['Reasoning'][i]:\n",
    "            hab25_plus+=1\n",
    "        elif 'Ease of Access' in df['Reasoning'][i]:\n",
    "            ease25_plus+=1\n",
    "        \n",
    "       \n",
    "x_labels = ['Sustainaility', 'Habit', 'Ease of Access']\n",
    "\n",
    "y_units_18 = [sus18, hab18, ease18]\n",
    "y_units_19 = [sus19, hab19, ease19]\n",
    "y_units_20 = [sus20, hab20, ease20]\n",
    "y_units_21 = [sus21, hab21, ease21]\n",
    "y_units_22 = [sus22, hab22, ease22]\n",
    "y_units_23 = [sus23, hab23, ease23]\n",
    "y_units_24 = [sus24, hab24, ease24]\n",
    "y_units_25 = [sus25, hab25, ease25]\n",
    "y_units_greater_25 = [sus25_plus, hab25_plus, ease25_plus]\n",
    "\n",
    "plt.plot(y_units_18, color='green')\n",
    "plt.plot(y_units_19, color='red')\n",
    "plt.plot(y_units_20, color='orange')\n",
    "plt.plot(y_units_21, color='purple')\n",
    "plt.plot(y_units_22, color='blue')\n",
    "plt.plot(y_units_23, color='black')\n",
    "plt.plot(y_units_24, color='pink')\n",
    "plt.plot(y_units_25, color='brown')\n",
    "plt.plot(y_units_greater_25, color='yellow')\n",
    "\n",
    "plt.title(\"Reasoning for Recycling Based on Age\")\n",
    "\n",
    "plt.xlabel('Reasons for Recycling')\n",
    "plt.ylabel('Number of People')\n",
    "plt.xticks(np.arange(len(x_labels)), x_labels, rotation=0)\n",
    "\n",
    "green_line = mpatches.Patch(color='green', label='18')\n",
    "red_line = mpatches.Patch(color='red', label='19')\n",
    "orange_line = mpatches.Patch(color='orange', label='20')\n",
    "purple_line = mpatches.Patch(color='purple', label='21')\n",
    "blue_line = mpatches.Patch(color='blue', label='22')\n",
    "black_line = mpatches.Patch(color='black', label='23')\n",
    "pink_line = mpatches.Patch(color='pink', label='24')\n",
    "brown_line = mpatches.Patch(color='brown', label='25')\n",
    "yellow_line = mpatches.Patch(color='yellow', label='>25')\n",
    "\n",
    "plt.legend(handles=[green_line, red_line, orange_line, purple_line, blue_line, black_line, pink_line,brown_line, yellow_line])\n",
    "\n",
    "plt.grid(True)\n",
    "           \n",
    "plt.show()\n",
    "\n",
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender Pie Chart\n",
    "fig6, ax6 = plt.subplots()\n",
    "labels = df1['Gender'].value_counts().index.tolist()\n",
    "\n",
    "wedges, texts, autotexts = ax6.pie(df1['Gender'].value_counts(), autopct='%1.1f%%', wedgeprops={'edgecolor': 'black'}, textprops=dict(color='w'))\n",
    "ax6.set_title('Number of Students per Gender')\n",
    "\n",
    "ax6.legend(loc=\"center right\", bbox_to_anchor=(1, 0, 0.5, 1), labels= labels)\n",
    "plt.setp(autotexts, size=12, weight=\"bold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year Pie Chart\n",
    "fig7, ax7 = plt.subplots()\n",
    "labels = df1['Year'].value_counts().index.tolist()\n",
    "\n",
    "wedges, texts, autotexts = ax7.pie(df1['Year'].value_counts(), autopct='%1.1f%%', wedgeprops={'edgecolor': 'black'}, textprops=dict(color='w'))\n",
    "ax7.set_title('Number of Students per Year')\n",
    "\n",
    "ax7.legend(loc=\"center right\", bbox_to_anchor=(1, 0, 0.5, 1), labels= labels)\n",
    "plt.setp(autotexts, size=12, weight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age v. Frequency Scatter plot\n",
    "fig8, ax8 = plt.subplots()\n",
    "\n",
    "ax8.scatter(df['Frequency_as_int'], df['Age'], marker='D', s=10, alpha=.5)\n",
    "x_axis = [\"\",\"Never\", \"Rarely\", \"Sometimes\", \"Often\", \"Always\"]\n",
    "ax8.set_xticklabels(x_axis)\n",
    "ax8.set_title('Recycling Frequency v. Age')\n",
    "ax8.set_xlabel('Recycling Frequency')\n",
    "ax8.set_ylabel('Age')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
